---
title: "p8105_hw5_xh2636"
author: "Xiaoyu Huang"
date: "2023-11-10"
output: github_document
---

```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
```

# Problem 1
```{r}
# Load the raw data
path <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data <- read.csv(path)
```

```{r, echo=FALSE}
obs <- nrow(homicide_data)
colum <- ncol(homicide_data)
```

The raw data is about `r obs` criminal homicides over the past decade in 50 of the largest American cities with `r colum` columns. The data included the location of the killing, whether an arrest was made and, in most cases, basic demographic information about each victim. 

```{r}
# Adding the city state variable
homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", "))

# Summarize within cities, the total number of homicides and the number of unsolved homicides
city_summary <- homicide_data %>%
  group_by(city_state) %>%
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", 
                                                "Open/No arrest"))
  )
```

```{r}
# Use the prop.test function to estimate the proportion of homicides that are unsolved
Baltimore_MD <- homicide_data %>%
  filter(city_state == "Baltimore, MD") %>%
  summarise(total_homicides = n(),
            unsolved_homicides = sum(disposition %in% c("Closed without arrest", 
                                                "Open/No arrest")))

# Apply the broom::tidy and pull the estimated proportion and confidence intervals
baltimore_test <- prop.test(x = pull(Baltimore_MD, unsolved_homicides)
                           , n = pull(Baltimore_MD, total_homicides)) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)

baltimore_test %>% knitr::kable()
```

```{r, warning=FALSE}
# Adding a function
prop_test_city <- function(city_all) {
  city_statesss <- city_all %>%
    summarise(total_homicides = n(), 
              unsolved_homicides = sum(disposition %in% c("Closed without arrest", 
                                                          "Open/No arrest")))

  city_test <- prop.test(x = pull(city_statesss, unsolved_homicides) , 
                       n = pull(city_statesss, total_homicides)) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)
  
  city_test
}

# Apply function to nested dataset and un-nest results
result_df <- homicide_data %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(result = map(data, prop_test_city)) %>%
  select(city_state, result) %>%
  unnest(cols = result)

print(result_df)
```

```{r}
# Arrange the city in estimate order and clean the dataframe
result_df <- result_df %>%
  filter(estimate != 0) %>%
  arrange(desc(estimate))

# Draw the graph
result_df %>%
  ggplot(aes(x = fct_reorder(city_state, -estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  coord_flip() +
  labs(title = "Proportion of Unsolved Homicides in Different Cities",
       x = "City",
       y = "Proportion of Unsolved Homicides") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Problem 2
```{r}
# Find the folder path
folder_path <- "./data/"

# Get all CSV files in the folder using "list.files"
data_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)

# Iterate over file names and read in data for each subject using purrr::map
all_data_csv <- map_df(data_files, ~{
  read.csv(.x) %>%
    mutate(subject_id = gsub("[^0-9]", "", basename(.x)),
           arm = ifelse(grepl("con", basename(.x)), "control", "experimental")) %>%
    gather(week, value, -subject_id, -arm) %>%
    mutate(week = as.numeric(gsub("\\D", "", week)))
})

view(all_data_csv)
```

```{r}
# Make a spaghetti plot showing observations on each subject over time
spaghetti_plot <- ggplot(all_data_csv, aes(x = week, y = value, group = subject_id)) +
  geom_line() +
  facet_grid(~arm) +
  labs(title = "Value of Observations Over Time",
       x = "Week",
       y = "Value") +
  theme(legend.position = "top")

print(spaghetti_plot)
```

As the graph, we can clearly see the different between control and experimental arm. The mean value for control group is lower than experimental, also same for the range of the value. Control arm have more negative value compare to experimental. Lastly, the fluctuation of the experimental curve is significantly greater than that of the control.

# Problem 3
