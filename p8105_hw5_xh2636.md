p8105_hw5_xh2636
================
Xiaoyu Huang
2023-11-10

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(ggplot2)
library(dplyr)
```

``` r
# Load the raw data
path <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data <- read.csv(path)
```

The raw data is about 52179 criminal homicides over the past decade in
50 of the largest American cities with 12 columns. The data included the
location of the killing, whether an arrest was made and, in most cases,
basic demographic information about each victim.

``` r
# Adding the city state variable
homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", "))

# Summarize within cities, the total number of homicides and the number of unsolved homicides
city_summary <- homicide_data %>%
  group_by(city_state) %>%
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", 
                                                "Open/No arrest"))
  )
```

``` r
# Use the prop.test function to estimate the proportion of homicides that are unsolved
Baltimore_MD <- homicide_data %>%
  filter(city_state == "Baltimore, MD") %>%
  summarise(total_homicides = n(),
            unsolved_homicides = sum(disposition %in% c("Closed without arrest", 
                                                "Open/No arrest")))

# Apply the broom::tidy and pull the estimated proportion and confidence intervals
baltimore_test <- prop.test(x = pull(Baltimore_MD, unsolved_homicides)
                           , n = pull(Baltimore_MD, total_homicides)) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)

baltimore_test %>% knitr::kable()
```

|  estimate |  conf.low | conf.high |
|----------:|----------:|----------:|
| 0.6455607 | 0.6275625 | 0.6631599 |

``` r
# Adding a function
prop_test_city <- function(city_all) {
  city_statesss <- city_all %>%
    summarise(total_homicides = n(), 
              unsolved_homicides = sum(disposition %in% c("Closed without arrest", 
                                                          "Open/No arrest")))

  city_test <- prop.test(x = pull(city_statesss, unsolved_homicides) , 
                       n = pull(city_statesss, total_homicides)) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)
  
  city_test
}

# Apply function to nested dataset and un-nest results
result_df <- homicide_data %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(result = map(data, prop_test_city)) %>%
  select(city_state, result) %>%
  unnest(cols = result)

print(result_df)
```

    ## # A tibble: 51 × 4
    ## # Groups:   city_state [51]
    ##    city_state      estimate conf.low conf.high
    ##    <chr>              <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM    0.386    0.337     0.438
    ##  2 Atlanta, GA        0.383    0.353     0.415
    ##  3 Baltimore, MD      0.646    0.628     0.663
    ##  4 Baton Rouge, LA    0.462    0.414     0.511
    ##  5 Birmingham, AL     0.434    0.399     0.469
    ##  6 Boston, MA         0.505    0.465     0.545
    ##  7 Buffalo, NY        0.612    0.569     0.654
    ##  8 Charlotte, NC      0.300    0.266     0.336
    ##  9 Chicago, IL        0.736    0.724     0.747
    ## 10 Cincinnati, OH     0.445    0.408     0.483
    ## # ℹ 41 more rows
